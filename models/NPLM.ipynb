{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T05:21:21.335016Z",
     "start_time": "2024-05-21T05:21:20.737621Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Neural Probabilistic Language Model, as described in Bengio et al. (2003)\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NPLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, context_size):\n",
    "        super(NPLM, self).__init__()\n",
    "        # Embedding layer\n",
    "        print(f'vocab_size: {vocab_size}')\n",
    "        print(f'embed_size: {embed_size}')\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_size)\n",
    "        print(f'embeddings: {self.embeddings}')\n",
    "        # Hidden layer\n",
    "        self.linear1 = nn.Linear(context_size * embed_size, hidden_size)\n",
    "        # Output layer\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "        # Activation functions\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Look up the embeddings for each context word and concatenate them\n",
    "        x = self.embeddings(x)\n",
    "        # Reshape the input to concatenate the embeddings\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass the concatenated embeddings through the first linear layer\n",
    "        x = self.linear1(x)\n",
    "        # Apply tanh activation function to introduce non-linearity\n",
    "        x = self.tanh(x)\n",
    "        # Pass the output through the second linear layer to get the scores for each word in the vocabulary\n",
    "        x = self.linear2(x)\n",
    "        # Apply softmax to get log-probabilities\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "## EXAMPLE USAGE:\n",
    "## Assuming `model_params` is a dictionary containing the model hyperparameters\n",
    "# model = NPLM(**model_params)\n",
    "# example_input = torch.tensor([[1, 2, 3, 4], [4, 3, 2, 1]], dtype=torch.long)\n",
    "# log_probs = model(example_input)\n",
    "# print(f'Output shape: {log_probs.shape}\\n')\n",
    "# print(f'Output: {log_probs}')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T05:22:52.776575Z",
     "start_time": "2024-05-21T05:22:51.128575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import load_arxiv_data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the dataset\n",
    "data = load_arxiv_data.load_arxiv_data(sample=True, columns=['title'])"
   ],
   "id": "b012c9af804723d1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T05:21:28.362245Z",
     "start_time": "2024-05-21T05:21:28.359192Z"
    }
   },
   "cell_type": "code",
   "source": "len(data)",
   "id": "939378a281c3677e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T05:23:12.907726Z",
     "start_time": "2024-05-21T05:23:12.903733Z"
    }
   },
   "cell_type": "code",
   "source": "data.head(10)",
   "id": "16feeae1518cebb7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title\n",
       "0  Double bit in-plane magnetic skyrmions on a track\n",
       "1  DDM: A Demand-based Dynamic Mitigation for SMT...\n",
       "2      Some new results in O(a) improved lattice QCD\n",
       "3  The behavior of magnetic ordering and the KOnd...\n",
       "4  The deepest X-ray view of high-redshift galaxi...\n",
       "5  Decomposed Linear Dynamical Systems (dLDS) for...\n",
       "6  The Magnetic Structure of Light Nuclei from La...\n",
       "7   Beyond NGS data sharing and towards open science\n",
       "8  Precipitation of Energetic Neutral Atoms and I...\n",
       "9  Orthros: Non-autoregressive End-to-end Speech ..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Double bit in-plane magnetic skyrmions on a track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDM: A Demand-based Dynamic Mitigation for SMT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some new results in O(a) improved lattice QCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The behavior of magnetic ordering and the KOnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The deepest X-ray view of high-redshift galaxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decomposed Linear Dynamical Systems (dLDS) for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Magnetic Structure of Light Nuclei from La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beyond NGS data sharing and towards open science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Precipitation of Energetic Neutral Atoms and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Orthros: Non-autoregressive End-to-end Speech ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T05:23:42.692160Z",
     "start_time": "2024-05-21T05:23:41.903954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "titles = data['title'].tolist()\n",
    "\n",
    "# Create a vocabulary\n",
    "vocab = set([word for title in titles for word in title])\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Create a mapping from words to indices\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Convert the titles to sequences of word indices\n",
    "titles = [[word_to_idx[word] for word in title] for title in titles]"
   ],
   "id": "3dbff4f8f0d0c090",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T05:31:14.028517Z",
     "start_time": "2024-05-21T05:31:14.024007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ArXivDataset class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ArXivDataset(Dataset):\n",
    "    pass\n",
    "\n",
    "def collate_fn(batch):\n",
    "    pass\n",
    "\n",
    "training_data = ArXivDataset(titles, context_size=2)\n",
    "data_loader = DataLoader(training_data, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ],
   "id": "6f5a9148852355",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T05:31:18.938993Z",
     "start_time": "2024-05-21T05:31:18.935833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "model_params = {\n",
    "    'vocab_size': len(vocab),  # Vocabulary size\n",
    "    'embed_size': 300,  # Dimension of word embeddings\n",
    "    'context_size': 2,  # Number of context words to consider\n",
    "    'hidden_size': 128  # Number of hidden units\n",
    "}"
   ],
   "id": "79b6bc455c8884d0",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T05:31:20.474694Z",
     "start_time": "2024-05-21T05:31:20.470394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = NPLM(**model_params)"
   ],
   "id": "c0084eeb773cdefb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 97\n",
      "embed_size: 300\n",
      "embeddings: Embedding(97, 300)\n"
     ]
    }
   ],
   "execution_count": 65
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
